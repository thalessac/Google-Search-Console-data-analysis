{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import easygui\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar como input desse programa um relatório com keywords, cliques, impressões e ranking position. Baseado no padrão do search console\n",
    "\n",
    "Escolher datasets de dois pontos no tempo para gerar comparação período sobre período\n",
    "\n",
    "Header da base de dados:\n",
    "| Top queries | Clicks | Impressions | Position |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read file and show dataframe\n",
    "\n",
    "#filename = easygui.fileopenbox() #In case we wish to select a file from file explorer\n",
    "\n",
    "filename = \"queries FS-january2022.csv\" #Current month dataset\n",
    "filename_prev = \"queries FS-december2021.csv\"#Previous month dataset\n",
    "current_month = \"January 2022\"\n",
    "previous_month = \"December 2021\"\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "df_prev = pd.read_csv(filename_prev)\n",
    "\n",
    "df.sort_values(by=['Impressions'], ascending=False, inplace=True)\n",
    "df_prev.sort_values(by=['Impressions'], ascending=False, inplace=True)\n",
    "\n",
    "# drop bad words\n",
    "todrop = df[ df['Top queries'].str.contains('porno|xxx|pono|mulher nua|mulheres nuas|mulheres nua|lesbicas|shemale|xvideo') ].index\n",
    "df.drop(todrop , inplace=True)\n",
    "\n",
    "# drop bad words df_prev\n",
    "todrop_prev = df_prev[ df_prev['Top queries'].str.contains('porno|xxx|pono|mulher nua|mulheres nuas|mulheres nua|lesbicas|shemale|xvideo') ].index\n",
    "df_prev.drop(todrop_prev , inplace=True)\n",
    "\n",
    "df['Top queries'] = df['Top queries'].str.replace('ps5','playstation 5')\n",
    "df_prev['Top queries'] = df_prev['Top queries'].str.replace('ps5','playstation 5')\n",
    "df['Top queries'] = df['Top queries'].str.replace('ps4','playstation 4')\n",
    "df_prev['Top queries'] = df_prev['Top queries'].str.replace('ps4','playstation 4')\n",
    "\n",
    "df_raw = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpeza e organização do dataset\n",
    "\n",
    "#Substituir todas as acentuações para agrupar possíveis grafias diferentes de uma mesma palavra\n",
    "def accent_replacement(df):\n",
    "    df['Top queries'] = df['Top queries'].str.replace('ã','a')\n",
    "    df['Top queries'] = df['Top queries'].str.replace('à','a')\n",
    "    df['Top queries'] = df['Top queries'].str.replace('á','a')\n",
    "    df['Top queries'] = df['Top queries'].str.replace('â','a')\n",
    "    df['Top queries'] = df['Top queries'].str.replace('é','e')\n",
    "    df['Top queries'] = df['Top queries'].str.replace('ê','e')\n",
    "    df['Top queries'] = df['Top queries'].str.replace('í','i')\n",
    "    df['Top queries'] = df['Top queries'].str.replace('ó','o')\n",
    "    df['Top queries'] = df['Top queries'].str.replace('õ','o')\n",
    "    df['Top queries'] = df['Top queries'].str.replace('ô','o')\n",
    "    df['Top queries'] = df['Top queries'].str.replace('ú','u')\n",
    "    df['Top queries'] = df['Top queries'].str.replace('ç','c')\n",
    "    #df['Top queries'] = df['Top queries'].str.replace('2021','') #Não considerar o termo do ano\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def text_to_vector(text):\n",
    "    WORD = re.compile(r\"\\w+\")\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "#Identificar search terms muito semelhantes para agrupar em um único termo\n",
    "def find_cosin_similarity(df):\n",
    "    \n",
    "    found = False\n",
    "    \n",
    "    kw_pairs = set(itertools.combinations(df['Top queries'].tolist(), 2))\n",
    "    \n",
    "    for pair in kw_pairs:\n",
    "        a = get_cosine(text_to_vector(pair[0]), text_to_vector(pair[1]))\n",
    "        if (a>=0.9):\n",
    "            df.loc[df['Top queries'] == pair[1], 'Top queries'] = pair[0]\n",
    "            found = True\n",
    "    \n",
    "    return found\n",
    "\n",
    "#Pivot table to aggregate same search term\n",
    "def aggr_kws(df):\n",
    "    df.loc[:,'prod'] = df.loc[:,'Impressions']*df.loc[:,'Position']\n",
    "    table = pd.pivot_table(df, values=['Clicks', 'Impressions', 'Position', 'prod'], index=['Top queries'], aggfunc={'Clicks': np.sum, 'Impressions': np.sum, 'Position' : np.sum, 'prod' : np.sum})\n",
    "    return table.reset_index()\n",
    "\n",
    "#Decide if the search query is a branded or unbranded term\n",
    "\n",
    "def branded_unbranded_decision(df):\n",
    "    \n",
    "    #Include branded search terms here\n",
    "    df['Branded'] = np.where(df['Top queries'].str.contains('amazon|kindle|echo|prime|alexa|fire stick|firetv|amaz|amzon|amazom|amaxon|amaozn|amozon|amaon|mazon|amazo|aamazon'), True, False)\n",
    "\n",
    "    #Generate two subsets with branded and unbranded keywords\n",
    "    df_branded = df[df['Branded'] == True]\n",
    "    df_unbranded = df[df['Branded'] == False]\n",
    "    \n",
    "    #Use create_calculated_impr_colums function to add columns on dataset\n",
    "    \n",
    "    return df_branded, df_unbranded\n",
    "\n",
    "#Create columns\n",
    "\n",
    "def create_calculated_columns (df):\n",
    "    '''Gets the raw dataset from GSC and create calculated columns with impressions (%)'''\n",
    "    \n",
    "    df.loc[:,'CTR'] = (df.loc[:,'Clicks']/df.loc[:,'Impressions'])*100  \n",
    "    df['CTR'] = df['CTR'].map('{:.2f}%'.format)\n",
    "    df.loc[:,'Position'] = df.loc[:,'prod']/df.loc[:,'Impressions']  \n",
    "    df['Position'] = df['Position'].map('{:.2f}'.format)\n",
    "    df.loc[:,'Impresions(%)'] = (df.loc[:,'Impressions']/df.loc[:,'Impressions'].sum())*100\n",
    "    df.loc[:,'Cum. impr. (%)'] = df.loc[:,'Impresions(%)'].cumsum()\n",
    "    return df\n",
    "\n",
    "def sortedSentence(sentence):\n",
    "      \n",
    "    words = sentence.split(\" \")\n",
    "    words.sort()\n",
    "    newSentence = \" \".join(words)\n",
    "\n",
    "    return newSentence\n",
    "\n",
    "def average_rank(df):\n",
    "    return np.average(df['Position'].astype(float))\n",
    "    \n",
    "def weighted_average_rank(df):\n",
    "    return np.average(df['Position'].astype(float), weights = df['Impressions'].astype(float))\n",
    "    \n",
    "def top_kw_count(df):\n",
    "    total_kws = len(df)\n",
    "    top3 = df['Position'][df['Position'].astype(float) <= 3].count()/total_kws\n",
    "    top5 = df['Position'][df['Position'].astype(float) <= 5].count()/total_kws\n",
    "    top10 = df['Position'][df['Position'].astype(float) <= 10].count()/total_kws\n",
    "    \n",
    "    return top3, top5, top10;\n",
    "\n",
    "def average_ctr(df):\n",
    "    return df['Clicks'].sum()/df['Impressions'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(df, isbranded):\n",
    "\n",
    "    keyword_list = df['Top queries'].tolist()\n",
    "    click_weight = df['Clicks'].tolist()\n",
    "\n",
    "    tokens = []\n",
    "    for t in range(len(keyword_list)):\n",
    "        for i in (keyword_list[t].split()):\n",
    "            if len(i)>1 and not i.isdigit(): #Considerar apenas palavras com conteúdo\n",
    "                for k in range(round(click_weight[t])):\n",
    "                    tokens.append(i)\n",
    "                    \n",
    "    ## Creating FreqDist for whole BoW, keeping the 20 most common tokens\n",
    "    all_fdist = nltk.FreqDist(tokens).most_common(20)\n",
    "\n",
    "    ## Conversion to Pandas series via Python Dictionary for easier plotting\n",
    "    all_fdist = pd.Series(dict(all_fdist))\n",
    "    \n",
    "    ## Setting figure, ax into variables\n",
    "    fig, ax = plt.subplots(figsize=(5,10))\n",
    "\n",
    "    ## Seaborn plotting using Pandas attributes + xtick rotation for ease of viewing\n",
    "    all_plot = sns.barplot(y=all_fdist.index, x=all_fdist.values, orient='h', ax=ax) \n",
    "    plt.xticks(rotation=30)\n",
    "    plt.xlabel('Count of clicks', fontsize = 12)\n",
    "    plt.ylabel('Search term', fontsize = 12)\n",
    "    \n",
    "    if isbranded == True:\n",
    "        plt.title('Branded Search\\n', fontsize = 15)\n",
    "        ax.annotate (\"'Amazon' and 'Prime' words are not considered\", xy=(0,1), xycoords='axes fraction', xytext = (10,10), textcoords='offset points')\n",
    "    elif isbranded == False:\n",
    "        plt.title('Unbranded Search\\n', fontsize = 15)\n",
    "    \n",
    "    return plt\n",
    "    \n",
    "#plt1 = word_frequency(df_branded, isbranded=True)\n",
    "#plt2 = word_frequency(df_unbranded, isbranded=False)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_term_freq(df, isbranded, title):\n",
    "    \n",
    "    df.sort_values(by=['Clicks'], ascending=False, inplace=True)\n",
    "    \n",
    "    keyword_list = df['Top queries'].head(20).tolist()\n",
    "    click_weight = df['Clicks'].head(20).tolist()\n",
    "    \n",
    "    all_fdist = pd.Series(dict(zip(keyword_list, click_weight)))\n",
    "   \n",
    "    ## Setting figure, ax into variables\n",
    "    fig, ax = plt.subplots(figsize=(5,10))\n",
    "\n",
    "    ## Seaborn plotting using Pandas attributes + xtick rotation for ease of viewing\n",
    "    all_plot = sns.barplot(y=all_fdist.index, x=all_fdist.values, orient='h', ax=ax, color = 'gray') \n",
    "    plt.xticks(rotation=30)\n",
    "    plt.xlabel('Count of clicks', fontsize = 12)\n",
    "    plt.ylabel('Search term', fontsize = 12)\n",
    "    \n",
    "    for p in ax.patches:\n",
    "        all_plot.annotate('{:,}'.format(round(p.get_width())), xy=(p.get_width(), p.get_y()+p.get_height()/2), xytext=(5, 0), textcoords='offset points', ha=\"right\", va=\"center\")\n",
    "    \n",
    "    if isbranded == True:\n",
    "        plt.title('Branded Search\\n', fontsize = 15)\n",
    "    elif isbranded == False:\n",
    "        plt.title('Unbranded Search - ' + title, fontsize = 15)\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(df, stopwords):\n",
    "    '''Recebe um dataframe e forma um gráfico de nuvens de palavras mais utilizadas nas strings de busca\n",
    "    df deve incluir uma coluna chamada 'Top queries' ''' \n",
    "    \n",
    "    # Create word list\n",
    "    text = \" \".join(review for review in df['Top queries'])\n",
    "\n",
    "    # Generate image\n",
    "    wordcloud = WordCloud(stopwords = stopwords, background_color=\"white\").generate(text)\n",
    "\n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "df['Top queries'] = df['Top queries'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "df_prev['Top queries'] = df_prev['Top queries'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "\n",
    "accent_replacement(df)\n",
    "accent_replacement(df_prev)\n",
    "\n",
    "df['Top queries'] = df['Top queries'].apply(sortedSentence) #ordenar search terms em ordem alfabetica\n",
    "df_prev['Top queries'] = df_prev['Top queries'].apply(sortedSentence)\n",
    "\n",
    "df = aggr_kws(df)\n",
    "df_prev = aggr_kws(df_prev)\n",
    "\n",
    "#agrupar kws semelhantes\n",
    "while (find_cosin_similarity(df)):\n",
    "    find_cosin_similarity(df)\n",
    "    df=aggr_kws(df)\n",
    "    \n",
    "while (find_cosin_similarity(df_prev)):\n",
    "    find_cosin_similarity(df_prev)\n",
    "    df_prev=aggr_kws(df_prev)\n",
    "\n",
    "df = create_calculated_columns(aggr_kws(df))\n",
    "df.drop('prod', axis=1, inplace=True)\n",
    "df_branded, df_unbranded = branded_unbranded_decision(df)\n",
    "\n",
    "df_prev = create_calculated_columns(aggr_kws(df_prev))\n",
    "df_prev.drop(['prod'], axis = 1, inplace=True)\n",
    "df_branded_prev, df_unbranded_prev = branded_unbranded_decision(df_prev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unbranded dataset visualization\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_unbranded.sort_values(by=['Clicks'], ascending=False, inplace=True)\n",
    "df_unbranded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Branded dataset visualization\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_branded.sort_values(by=['Clicks'], ascending=False, inplace=True)\n",
    "df_branded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Search term frequency\n",
    "plt1 = search_term_freq(df_unbranded, False, current_month)\n",
    "plt2 = search_term_freq(df_unbranded_prev, False, previous_month)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Ranking statistics\n",
    "\n",
    "nl = '\\n'\n",
    "\n",
    "print(f\"Average rank: {average_rank(df_unbranded):.2f}{nl}Weighted average rank: {weighted_average_rank(df_unbranded):.2f}{nl}Average CTR: {average_ctr(df_unbranded):.2%}{nl}Top 3 kw kw share: {top_kw_count(df_unbranded)[0]:.2%}\")\n",
    "print(f\"Top 5 kw kw share: {top_kw_count(df_unbranded)[1]:.2%}{nl}Top 10 kw kw share: {top_kw_count(df_unbranded)[2]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MoM keywords comparisom\n",
    "\n",
    "df_unbranded.sort_values(by=['Clicks'], ascending=False, inplace=True)\n",
    "df_unbranded_prev.sort_values(by=['Clicks'], ascending=False, inplace=True)\n",
    "\n",
    "kws_current_month = set(df_unbranded['Top queries'].head(20).apply(lambda x: sortedSentence(x)))\n",
    "kws_previous_month = set(df_unbranded_prev['Top queries'].head(20).apply(lambda x: sortedSentence(x)))\n",
    "\n",
    "\n",
    "print(\"Out of Top-20: \")\n",
    "print(kws_previous_month - kws_current_month)\n",
    "\n",
    "print(\"\\nInto of Top-20: \")\n",
    "print(kws_current_month - kws_previous_month)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud(df_branded, stopwords)\n",
    "word_cloud(df_unbranded, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining data into one single dataframe for MoM comparisson\n",
    "\n",
    "df_comb = df_unbranded.join(df_unbranded_prev.set_index('Top queries'), on = 'Top queries', how='outer', lsuffix=' current', rsuffix=' previous', sort=False)\n",
    "df_comb\n",
    "\n",
    "df_comb['Clicks variation'] =  df_comb['Clicks current']/df_comb['Clicks previous'] - 1\n",
    "df_comb['Ranking variation'] =  df_comb['Position previous'].astype(float) - df_comb['Position current'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topx = 5 #How many top keywords to display\n",
    "\n",
    "#TOP GROWING KEYWORDS\n",
    "top_growing_kws = df_comb[(df_comb['Clicks current'] >= 500) | (df_comb['Clicks previous'] >= 500)]\n",
    "top_growing_kws.sort_values(by=['Clicks variation'], ascending=False, inplace=True)\n",
    "top_growing_kws.index = pd.RangeIndex(start=1, stop=len(top_growing_kws)+1, step=1)\n",
    "print(\"\\nTOP GROWING KEYWORDS\")\n",
    "top_growing_kws = top_growing_kws[['Top queries', 'Clicks current', 'Clicks previous', 'Clicks variation']].head(topx)\n",
    "display(top_growing_kws)\n",
    "\n",
    "#TOP DESCENDING KEYWORDS\n",
    "top_desc_kws = df_comb[(df_comb['Clicks current'] >= 500) | (df_comb['Clicks previous'] >= 500)]\n",
    "top_desc_kws.sort_values(by=['Clicks variation'], ascending=True, inplace=True)\n",
    "top_desc_kws.index = pd.RangeIndex(start=1, stop=len(top_desc_kws)+1, step=1)\n",
    "print(\"\\nTOP DESCENDING KEYWORDS\")\n",
    "top_desc_kws = top_desc_kws[['Top queries', 'Clicks current', 'Clicks previous', 'Clicks variation']].head(topx)\n",
    "display(top_desc_kws)\n",
    "\n",
    "#TOP RANK GROWTH\n",
    "top_rank_growth = df_comb[(df_comb['Clicks current'] >= 500) | (df_comb['Clicks previous'] >= 500)]\n",
    "top_rank_growth.sort_values(by=['Ranking variation'], ascending=False, inplace=True)\n",
    "top_rank_growth.index = pd.RangeIndex(start=1, stop=len(top_rank_growth)+1, step=1)\n",
    "print(\"\\nTOP RANK GROWTH\")\n",
    "top_rank_growth = top_rank_growth[['Top queries', 'Position current', 'Position previous', 'Ranking variation']].head(topx)\n",
    "display(top_rank_growth)\n",
    "\n",
    "#TOP RANK DECLINE\n",
    "top_rank_decl = df_comb[(df_comb['Clicks current'] >= 500) | (df_comb['Clicks previous'] >= 500)]\n",
    "top_rank_decl.sort_values(by=['Ranking variation'], ascending=True, inplace=True)\n",
    "top_rank_decl.index = pd.RangeIndex(start=1, stop=len(top_rank_decl)+1, step=1)\n",
    "print(\"\\nTOP RANK DECLINE\")\n",
    "top_rank_decl = top_rank_decl[['Top queries', 'Position current', 'Position previous', 'Ranking variation']].head(topx)\n",
    "display(top_rank_decl)\n",
    "\n",
    "#TOP NEW KEYWORDS\n",
    "top_new_kw = df_comb[(df_comb['Clicks current'] > 0) & (df_comb['Clicks previous'].isnull())]\n",
    "top_new_kw.sort_values(by=['Clicks current'], ascending=False, inplace=True)\n",
    "top_new_kw.index = pd.RangeIndex(start=1, stop=len(top_new_kw)+1, step=1)\n",
    "print(\"\\nTOP NEW KEYWORDS\")\n",
    "top_new_kw = top_new_kw[['Top queries', 'Position current', 'Clicks current']].head(topx)\n",
    "display(top_new_kw)\n",
    "\n",
    "#HIGH CTR KEYWORDS\n",
    "high_ctr_kws = df_comb.copy()\n",
    "high_ctr_kws.sort_values(by=['CTR current'], ascending=False, inplace=True)\n",
    "high_ctr_kws.index = pd.RangeIndex(start=1, stop=len(high_ctr_kws)+1, step=1)\n",
    "print(\"\\nHIGH CTR KEYWORDS\")\n",
    "high_ctr_kws = high_ctr_kws[['Top queries', 'Clicks current', 'Impressions current', 'CTR current']].head(2*topx)\n",
    "display(high_ctr_kws)\n",
    "\n",
    "#LOW CTR KEYWORDS\n",
    "#low_ctr_kws = df_comb[(df_comb['Clicks current'] >= 500) | (df_comb['Clicks previous'] >= 500)]\n",
    "low_ctr_kws = df_comb.copy()\n",
    "low_ctr_kws.sort_values(by=['CTR current'], ascending=True, inplace=True)\n",
    "low_ctr_kws.index = pd.RangeIndex(start=1, stop=len(low_ctr_kws)+1, step=1)\n",
    "print(\"\\nLOW CTR KEYWORDS\")\n",
    "low_ctr_kws = low_ctr_kws[['Top queries', 'Clicks current', 'Impressions current', 'CTR current']].head(2*topx)\n",
    "display(low_ctr_kws)\n",
    "\n",
    "titles = [\"Top growing keywords\", \"Top descending keywords\", \"Top rank growth\", \"Top ranking decline\", \"Top new keywords\", \"High CTR keywords\", \"Low CTR keywords\"]\n",
    "tables = [top_growing_kws, top_desc_kws, top_rank_growth, top_rank_decl, top_new_kw, high_ctr_kws, low_ctr_kws]\n",
    "\n",
    "#Write tables on Excel\n",
    "writer = pd.ExcelWriter('kws_analysis.xlsx', engine='xlsxwriter')\n",
    "row = 0\n",
    "for title, table in zip(titles, tables):\n",
    "    table.to_excel(writer, sheet_name='Sheet1', startrow=row+1)  \n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "    worksheet.write(row, 0, title)\n",
    "    row += len(table) + 3\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_querie(df):\n",
    "    string = str(input(\"Buscar palavra chave:\"))\n",
    "    recorte = df[df['Top queries'].str.contains(string)].iloc[:,0:4]\n",
    "    print(\"Total de cliques: \", sum(recorte['Clicks']) )\n",
    "    return recorte\n",
    "    \n",
    "buscar_querie(df_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
